#!/usr/bin/env python
# coding: utf-8

# # **SPEECH EMOTION RECOGNITION MODEL**
# 

# ## **IMPORTING THE REQUIRED DEPENDENCIES**
# **REQUIRED LIBRARIES ARE IMPORTED**

# In[77]:


import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import os
import librosa
from IPython.display import Audio
import librosa.display


# 

# ### **DATASET LOADING**

# 

# In[78]:


paths = []
labels = []
for dirname, _, filenames in os.walk("/kaggle/input/toronto-emotional-speech-set-tess"):
    for filename in filenames:
        paths.append(os.path.join(dirname, filename))
        label = filename.split('_')[-1]
        label = label.split('.')[0]
        labels.append(label.lower())
    if len(paths) == 2800:
        break

print("DATASET HAS BEEN LOADED")        
        
        


# 

# **DATA OBSERVATION**
# **OBSERVING THE DATA TO GET SOME UNDERSTANDING OVER THE DATASET**

# ****

# **CREATING DATAFRAME**

# In[79]:


dtf= pd.DataFrame()
dtf['labels'] = labels
dtf['speech'] = paths


# 

# In[80]:


dtf.describe()


# In[109]:


dtf['speech'].value_counts()


# In[110]:


dtf.head()


# In[83]:


dtf['labels'].value_counts()


# ### VISUALIZING DATA
# **DEFINING WAVEPLOT FUNCTION**

# In[84]:


def wvplt(dt, sr, emtn):
    plt.figure(figsize=(12,6))
    plt.title(emtn, size = 19)
    librosa.display.waveshow(dt, sr=sr)
    plt.show()


# **DEFINING SPECTOGRAM**

# In[85]:


def sptm(dt, sr, emtn):
    x= librosa.stft(dt)
    x_db= librosa.amplitude_to_db(abs(x))
    plt.figure(figsize=(12,6))
    plt.title(emtn, size=20)
    librosa.display.specshow(x_db, sr=sr, x_axis='time',y_axis='hz')
    plt.colorbar()


# **HAPPY**

# In[86]:


emtn ='happy'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# In[ ]:





# **NEUTRAL**

# In[107]:


emtn ='neutral'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# **PLESAENT SURPRISE**

# In[88]:


emtn ='ps'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# **ANGRY**

# In[89]:


emtn ='angry'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# **FEAR**

# In[90]:


emtn ='fear'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# **SAD**

# In[91]:


emtn ='sad'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# **DISGUST**

# In[92]:


emtn ='disgust'
path = np.array(df['speech'][df['label']== emtn])[1]
data,sam_rt = librosa.load(path)
wvplt(data,sam_rt,emtn)
sptm(data,sam_rt,emtn)


# In[93]:


def com_mfcc(filename):
    y,sr=librosa.load(filename, duration=3, offset=0.5)
    mfccs=librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)
    avg_mfccs= np.mean(mfccs.T, axis=0)
    return avg_mfccs


# In[94]:


com_mfcc(df['speech'][0])


# In[95]:


c_mfcc=df['speech'].apply(lambda x: com_mfcc(x))
c_mfcc


# In[96]:


c_x=[x for x in c_mfcc]
c_x=np.array(c_x)
c_x.shape


# In[97]:


c_x=np.expand_dims(c_x,-1)
c_x.shape


# 

# #### MODEL TRAINING AND PREDICTION

# 

# In[98]:


from sklearn.preprocessing import OneHotEncoder
encd = OneHotEncoder()
c_y=encd.fit_transform(dtf[['labels']])
c_y=c_y.toarray()


# 

# **MODEL CREATION(l)**

# In[99]:


from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(c_x,c_y,test_size=0.20, random_state=30)


# In[100]:


from keras.models import Sequential
from keras.layers import Dense, LSTM, Dropout

model= Sequential([
    LSTM(256, return_sequences=False, input_shape=(40,1)),
    Dropout(0.2),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(7, activation='softmax')
])

model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.summary


# 

# **TRAINING THE MODEL**

# In[101]:


P=model.fit(x_train,y_train,validation_split=0.2,epochs=23, batch_size=64,shuffle=True)


# In[103]:


model.evaluate(x_train, y_train)


# In[104]:


Y_P=model.predict(x_test, batch_size=6)


# In[105]:


accuracy_s=model.evaluate(x_test,y_test)

